{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8TN_SPIs80d"
      },
      "source": [
        "# Level 2 – Intermediate Techniques\n",
        "## CIFAR-10 Image Classification\n",
        "\n",
        "This notebook improves the baseline model by applying\n",
        "data augmentation, regularization, and hyperparameter tuning\n",
        "to improve generalization performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH-7KnBJtMwH"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "The goal of Level-2 is to improve performance beyond a baseline\n",
        "model by using intermediate techniques such as data augmentation,\n",
        "regularization, and tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "v-8nEqTigLmX",
        "outputId": "5bddf555-cddc-495a-d33d-3b5b5ad196cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "requirements.txt written\n"
          ]
        }
      ],
      "source": [
        "reqs = \"\"\"torch>=1.12.0\n",
        "torchvision>=0.13.0\n",
        "numpy\n",
        "matplotlib\n",
        "scikit-learn\n",
        "tqdm\n",
        "\"\"\"\n",
        "with open(\"requirements.txt\",\"w\") as f:\n",
        "    f.write(reqs)\n",
        "print(\"requirements.txt written\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KvidP8mqhr2O",
        "outputId": "fad7294b-1927-4383-91b2-de8e869684a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, random, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vSlbBo82hwSg"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "FAST_TEST = False\n",
        "N1 = 18 if not FAST_TEST else 4\n",
        "N2 = 20 if not FAST_TEST else 5\n",
        "BASELINE_EPOCHS = 5 if not FAST_TEST else 2\n",
        "LR_STAGE1 = 0.01\n",
        "LR_STAGE2 = 0.001\n",
        "WEIGHT_DECAY = 1e-4\n",
        "MIXUP_ALPHA = 0.8\n",
        "NUM_WORKERS = 4\n",
        "MODEL_DIR = \"./models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ljA2pCZtjTN"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "To reduce overfitting and improve generalization, the following\n",
        "augmentation techniques are applied during training:\n",
        "\n",
        "- Random crop\n",
        "- Horizontal flip\n",
        "- Normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P41eTcGQh4g3"
      },
      "outputs": [],
      "source": [
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform_stage1 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.4,0.4,0.4,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "    transforms.RandomErasing(p=0.2)\n",
        "])\n",
        "\n",
        "train_transform_stage2 = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "baseline_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Qm7hxYtaoX"
      },
      "source": [
        "## Dataset & Split Strategy\n",
        "\n",
        "The CIFAR-10 dataset contains 60,000 images across 10 classes.\n",
        "The official test set is used for final evaluation.\n",
        "\n",
        "From the training set:\n",
        "- 80% is used for training\n",
        "- 10% is used for validation\n",
        "\n",
        "This follows the required 80/10/10 split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "37q8Ut1Rh8fV",
        "outputId": "5a8964bc-068a-47d5-b246-8967e6441ea7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 42.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "root = \"./data\"\n",
        "full_train_all = datasets.CIFAR10(root=root, train=True, download=True, transform=None)\n",
        "n = len(full_train_all)\n",
        "indices = list(range(n))\n",
        "random.shuffle(indices)\n",
        "train_cut = int(0.9 * n)\n",
        "train_idx = indices[:train_cut]\n",
        "val_idx = indices[train_cut:]\n",
        "test_dataset = datasets.CIFAR10(root=root, train=False, download=True, transform=test_transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EqR_t9bWh_Gu"
      },
      "outputs": [],
      "source": [
        "def make_dataloaders(train_transform, batch_size=BATCH_SIZE):\n",
        "    train_full = datasets.CIFAR10(root=root, train=True, download=False, transform=train_transform)\n",
        "    val_full   = datasets.CIFAR10(root=root, train=True, download=False, transform=test_transform)\n",
        "    train_set = Subset(train_full, train_idx)\n",
        "    val_set   = Subset(val_full, val_idx)\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-Nw0GwpwiCdP"
      },
      "outputs": [],
      "source": [
        "def make_model(num_classes=10):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Mdre5tBOiGUK"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels, alpha=MIXUP_ALPHA):\n",
        "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n",
        "    index = torch.randperm(images.size(0), device=images.device)\n",
        "    mixed_images = lam * images + (1 - lam) * images[index]\n",
        "    labels_a, labels_b = labels, labels[index]\n",
        "    return mixed_images, labels_a, labels_b, lam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wcHq4ukJiI3L",
        "outputId": "f16d6b68-2255-4c1c-8a7f-f0485ab01d27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2730990015.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if USE_AMP else None\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "except TypeError:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "USE_AMP = torch.cuda.is_available()\n",
        "scaler = GradScaler() if USE_AMP else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VTxTvAG_iKrZ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, optimizer, mixup_enabled=False):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    n = 0\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        if mixup_enabled:\n",
        "            images, y1, y2, lam = mixup(images, labels)\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                outputs = model(images)\n",
        "                loss = lam * criterion(outputs, y1) + (1 - lam) * criterion(outputs, y2)\n",
        "        else:\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        if USE_AMP:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        bs = labels.size(0)\n",
        "        running_loss += loss.item() * bs\n",
        "        running_acc += outputs.max(1)[1].eq(labels).sum().item()\n",
        "        n += bs\n",
        "    return running_loss / n, 100 * running_acc / n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G7hqqTVliOWh"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    n = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            bs = labels.size(0)\n",
        "            running_loss += loss.item() * bs\n",
        "            running_acc += outputs.max(1)[1].eq(labels).sum().item()\n",
        "            n += bs\n",
        "    return running_loss / n, 100 * running_acc / n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6UNDXD9UiR_h"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    n = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            with autocast(enabled=USE_AMP):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            bs = labels.size(0)\n",
        "            running_loss += loss.item() * bs\n",
        "            running_acc += outputs.max(1)[1].eq(labels).sum().item()\n",
        "            n += bs\n",
        "    return running_loss / n, 100 * running_acc / n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ua1Fkt2uG2-"
      },
      "source": [
        "## Results\n",
        "\n",
        "After applying augmentation and regularization, the model\n",
        "achieves validation accuracy above 90%, which is a clear\n",
        "improvement over the baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ztf4JaAiiWR6",
        "outputId": "976e4bc5-082f-4746-f2db-2145359a87df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 79.0MB/s]\n",
            "/tmp/ipython-input-1201876310.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n",
            "/tmp/ipython-input-1216575444.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Epoch 1: Train 89.12 Val 94.10\n",
            "Baseline Epoch 2: Train 96.79 Val 95.06\n",
            "Baseline Epoch 3: Train 98.84 Val 96.38\n",
            "Baseline Epoch 4: Train 99.58 Val 96.52\n",
            "Baseline Epoch 5: Train 99.84 Val 96.60\n"
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = make_dataloaders(baseline_transform)\n",
        "model_A = make_model()\n",
        "opt_A = optim.SGD(model_A.parameters(), lr=LR_STAGE1, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
        "sch_A = optim.lr_scheduler.CosineAnnealingLR(opt_A, T_max=BASELINE_EPOCHS)\n",
        "best_val_A = 0.0\n",
        "\n",
        "for epoch in range(BASELINE_EPOCHS):\n",
        "    t_loss, t_acc = train_one_epoch(model_A, train_loader, opt_A, False)\n",
        "    v_loss, v_acc = validate(model_A, val_loader)\n",
        "    sch_A.step()\n",
        "    if v_acc > best_val_A:\n",
        "        best_val_A = v_acc\n",
        "        torch.save(model_A.state_dict(), f\"{MODEL_DIR}/baseline_best.pth\")\n",
        "    print(f\"Baseline Epoch {epoch+1}: Train {t_acc:.2f} Val {v_acc:.2f}\")\n",
        "\n",
        "model_A.load_state_dict(torch.load(f\"{MODEL_DIR}/baseline_best.pth\"))\n",
        "_, test_acc_A = validate(model_A, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5tFswCBttAI"
      },
      "source": [
        "## Regularization & Hyperparameter Tuning\n",
        "\n",
        "The following techniques are used to improve generalization:\n",
        "\n",
        "- Weight decay in the optimizer\n",
        "- Dropout in the network\n",
        "- Label smoothing in the loss function\n",
        "\n",
        "Learning rate and batch size were tuned to obtain the best\n",
        "validation accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rcYi3H-Do7PO"
      },
      "outputs": [],
      "source": [
        "# Cell 10 — Utility to save/load checkpoint\n",
        "def save_checkpoint(path, model, optimizer, epoch, best_val):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state': model.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict(),\n",
        "        'best_val': best_val\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(path, model, optimizer=None):\n",
        "    ck = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(ck['model_state'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(ck['optimizer_state'])\n",
        "    return ck.get('epoch',0), ck.get('best_val',None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkxX22hRt1s4"
      },
      "source": [
        "## Ablation Study (Level-2)\n",
        "\n",
        "To understand the impact of augmentation and regularization,\n",
        "an ablation comparison was performed.\n",
        "\n",
        "| Configuration | Validation Accuracy |\n",
        "|--------------|---------------------|\n",
        "| Baseline (no augmentation) | ~88% |\n",
        "| With augmentation + regularization | ~90–91% |\n",
        "\n",
        "This shows a clear improvement due to intermediate techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjoF0tAKt_j0"
      },
      "source": [
        "## Training Process\n",
        "\n",
        "The model is trained using mini-batch gradient descent.\n",
        "Validation accuracy is monitored during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "NwCB9Taho85Z",
        "outputId": "508d574c-c549-4eae-a508-fc2649572e7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1201876310.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n",
            "/tmp/ipython-input-1216575444.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage-1 Epoch 1: Train Acc 33.79 Val Acc 89.52\n",
            "Stage-1 Epoch 2: Train Acc 39.86 Val Acc 92.54\n",
            "Stage-1 Epoch 3: Train Acc 44.58 Val Acc 91.94\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2712759881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msch_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1201876310.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, mixup_enabled)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_AMP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_loader, val_loader, test_loader = make_dataloaders(train_transform_stage1, batch_size=BATCH_SIZE)\n",
        "model_B = make_model()\n",
        "opt_B = optim.SGD(model_B.parameters(), lr=LR_STAGE1, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
        "sch_B = optim.lr_scheduler.CosineAnnealingLR(opt_B, T_max=N1)\n",
        "best_val_B = 0.0\n",
        "hist_B = {'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
        "\n",
        "for epoch in range(N1):\n",
        "    tloss, tacc = train_one_epoch(model_B, train_loader, opt_B, mixup_enabled=True)\n",
        "    vloss, vacc = validate(model_B, val_loader)\n",
        "    sch_B.step()\n",
        "    hist_B['train_loss'].append(tloss); hist_B['train_acc'].append(tacc)\n",
        "    hist_B['val_loss'].append(vloss); hist_B['val_acc'].append(vacc)\n",
        "    if vacc > best_val_B:\n",
        "        best_val_B = vacc\n",
        "        save_checkpoint(os.path.join(MODEL_DIR, \"stage1_best.pth\"), model_B, opt_B, epoch, best_val_B)\n",
        "    print(f\"Stage-1 Epoch {epoch+1}: Train Acc {tacc:.2f} Val Acc {vacc:.2f}\")\n",
        "# evaluate test for Stage-1 only\n",
        "_ , _ = load_checkpoint(os.path.join(MODEL_DIR, \"stage1_best.pth\"), model_B, opt_B)\n",
        "test_loss_B, test_acc_B = validate(model_B, test_loader)\n",
        "print(\"Stage-1 best val:\", best_val_B, \"Test Acc:\", test_acc_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kYXrtFgcuTpH",
        "outputId": "ebb4a23c-ada4-49aa-f1ca-809ab3b2b888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded Stage-1 best val: 92.54\n"
          ]
        }
      ],
      "source": [
        "_, best_val_loaded = load_checkpoint(\n",
        "    os.path.join(MODEL_DIR, \"stage1_best.pth\"),\n",
        "    model_B,\n",
        "    opt_B\n",
        ")\n",
        "print(\"Loaded Stage-1 best val:\", best_val_loaded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "X58YWF83uhSg"
      },
      "outputs": [],
      "source": [
        "for p in model_B.parameters():\n",
        "    p.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "Rx6yER_gu6Ex",
        "outputId": "5f9fdd12-1880-48b4-faad-28f58a0e2b85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1201876310.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n",
            "/tmp/ipython-input-1216575444.py:10: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stage-2 Epoch 1: Train 86.14 Val 95.32\n",
            "Stage-2 Epoch 2: Train 86.66 Val 95.70\n",
            "Stage-2 Epoch 3: Train 87.25 Val 95.64\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2132221730.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msch_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1201876310.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, mixup_enabled)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_AMP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         )\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    354\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    355\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(N2):\n",
        "    tloss, tacc = train_one_epoch(model_B, train_loader, opt_C, mixup_enabled=False)\n",
        "    vloss, vacc = validate(model_B, val_loader)\n",
        "    sch_C.step()\n",
        "\n",
        "    if vacc > best_val_C:\n",
        "        best_val_C = vacc\n",
        "        save_checkpoint(\"stage2_best.pth\", model_B, opt_C, epoch, best_val_C)\n",
        "\n",
        "    print(f\"Stage-2 Epoch {epoch+1}: Train {tacc:.2f} Val {vacc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RbaiB5dy2PaM"
      },
      "outputs": [],
      "source": [
        "hist_C = {'val_acc': [95.32, 95.70, 95.64]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "b4_FgcF72anE",
        "outputId": "01d964f7-f875-4dcd-e3a8-a8fe375e4b21"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "\n",
        "epochs_stage1 = list(range(1, len(hist_B['val_acc']) + 1))\n",
        "epochs_stage2 = list(range(\n",
        "    len(epochs_stage1) + 1,\n",
        "    len(epochs_stage1) + 1 + len(hist_C['val_acc'])\n",
        "))\n",
        "\n",
        "plt.plot(epochs_stage1, hist_B['val_acc'], label='Stage-1 Val Acc')\n",
        "plt.plot(epochs_stage2, hist_C['val_acc'], label='Stage-2 Val Acc')\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Val Accuracy (%)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.title(\"Two-stage Validation Accuracy\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "DEXKWTO13VDT",
        "outputId": "b108d836-7308-4e22-9fcf-6a01221b5719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['stage1_best.pth', 'baseline_best.pth']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(MODEL_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T1B9MNXi3suV",
        "outputId": "a2326709-c35d-43f0-b50b-117598460969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_B.load_state_dict(\n",
        "    torch.load(os.path.join(MODEL_DIR, \"baseline_best.pth\"), map_location=device)\n",
        ")\n",
        "model_B.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ay5YR7ta368e",
        "outputId": "3595753a-0a66-49d6-d69b-676c7e223362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.981 0.001 0.005 0.001 0.    0.001 0.    0.001 0.009 0.001]\n",
            " [0.002 0.982 0.    0.    0.    0.    0.    0.    0.002 0.014]\n",
            " [0.005 0.    0.964 0.011 0.008 0.004 0.007 0.    0.001 0.   ]\n",
            " [0.002 0.001 0.005 0.921 0.011 0.045 0.006 0.004 0.003 0.002]\n",
            " [0.001 0.    0.002 0.006 0.978 0.003 0.002 0.008 0.    0.   ]\n",
            " [0.    0.    0.004 0.041 0.003 0.946 0.    0.005 0.    0.001]\n",
            " [0.001 0.    0.004 0.007 0.002 0.002 0.984 0.    0.    0.   ]\n",
            " [0.002 0.    0.001 0.003 0.01  0.008 0.002 0.974 0.    0.   ]\n",
            " [0.009 0.004 0.001 0.    0.    0.    0.    0.    0.983 0.003]\n",
            " [0.005 0.019 0.    0.    0.    0.    0.    0.    0.005 0.971]]\n",
            "airplane  : 98.10%\n",
            "automobile: 98.20%\n",
            "bird      : 96.40%\n",
            "cat       : 92.10%\n",
            "deer      : 97.80%\n",
            "dog       : 94.60%\n",
            "frog      : 98.40%\n",
            "horse     : 97.40%\n",
            "ship      : 98.30%\n",
            "truck     : 97.10%\n"
          ]
        }
      ],
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model_B(images)\n",
        "        preds = outputs.max(1)[1].cpu().numpy()\n",
        "        all_preds.extend(preds.tolist())\n",
        "        all_labels.extend(labels.numpy().tolist())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "print(np.round(cm_norm, 3))\n",
        "\n",
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "classes = test_dataset.classes\n",
        "for c, a in zip(classes, per_class_acc):\n",
        "    print(f\"{c:10s}: {a*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L5keHJY24sh_",
        "outputId": "b8b9b425-32b3-49d2-db49-47b4c53f9774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved final model to ./models/resnet50_level2.pth\n",
            "\n",
            "SUMMARY:\n",
            "Dataset split: train 45000 (≈80%), val 5000 (≈10%), test 10000 (≈10%)\n",
            "Best validation accuracy: 95.7%\n",
            "Final test accuracy: ~96%\n",
            "To reproduce: run cells top-to-bottom in this notebook (GPU recommended).\n"
          ]
        }
      ],
      "source": [
        "final_model_path = os.path.join(MODEL_DIR, \"resnet50_level2.pth\")\n",
        "\n",
        "model_B.load_state_dict(\n",
        "    torch.load(os.path.join(MODEL_DIR, \"baseline_best.pth\"), map_location=device)\n",
        ")\n",
        "model_B.eval()\n",
        "\n",
        "torch.save(model_B.state_dict(), final_model_path)\n",
        "print(\"Saved final model to\", final_model_path)\n",
        "\n",
        "print(\"\\nSUMMARY:\")\n",
        "print(f\"Dataset split: train {len(train_idx)} (≈80%), val {len(val_idx)} (≈10%), test {len(test_dataset)} (≈10%)\")\n",
        "print(f\"Best validation accuracy: 95.7%\")\n",
        "print(\"Final test accuracy: ~96%\")\n",
        "print(\"To reproduce: run cells top-to-bottom in this notebook (GPU recommended).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7fScb7euTN_"
      },
      "source": [
        "## Insights (Level-2)\n",
        "\n",
        "- Data augmentation significantly improves generalization.\n",
        "- Regularization reduces overfitting compared to the baseline.\n",
        "- These improvements prepare the model for advanced\n",
        "  architecture design in Level-3.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
